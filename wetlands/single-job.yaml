apiVersion: batch/v1
kind: Job
metadata:
  name: slow-data-job
  labels:
    k8s-app: data-job
spec:
  completions: 1
  parallelism: 1  # adjust concurrency as cluster capacity allows
  completionMode: Indexed
  backoffLimit: 0
  # Keep failed pods (seconds) for debugging
  ttlSecondsAfterFinished: 36000
  template:
    metadata:
      labels:
        k8s-app: data-job
    spec:
      # allow others to pre-empt the pods, required for large CPU jobs
      priorityClassName: opportunistic
      # Avoid GPU nodes which can hit trouble.  also recommended for large CPU-only jobs.
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: feature.node.kubernetes.io/pci-10de.present
                operator: NotIn
                values:
                - "true"
      # Keep failed pods around for debugging (paired with ttlSecondsAfterFinished at job level)
      # Never restart pod on failure - keep failed pods for debugging
      restartPolicy: Never
      initContainers:
        - name: git-clone
          image: alpine/git:2.45.2
          imagePullPolicy: IfNotPresent
          resources:
            requests:
              cpu: "1"
              memory: 1Gi
            limits:
              cpu: "1"
              memory: 1Gi
          command:
            - sh
            - -lc
            - |
              git clone --depth 1 "https://github.com/boettiger-lab/datasets.git" /workspace/datasets
          volumeMounts:
            - name: repo
              mountPath: /workspace
      containers:
        - name: data-task
          image: ghcr.io/rocker-org/ml-spatial
          imagePullPolicy: Always
          workingDir: /workspace/datasets
          volumeMounts:
            - name: repo
              mountPath: /workspace
          env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: aws
                  key: AWS_ACCESS_KEY_ID
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aws
                  key: AWS_SECRET_ACCESS_KEY
            - name: MINIO_KEY
              valueFrom:
                secretKeyRef:
                  name: nvme
                  key: MINIO_KEY
            - name: MINIO_SECRET
              valueFrom:
                secretKeyRef:
                  name: nvme
                  key: MINIO_SECRET
            - name: MINIO_ENDPOINT
              valueFrom:
                secretKeyRef:
                  name: nvme
                  key: MINIO_ENDPOINT
            - name: AWS_S3_ENDPOINT
              value: "rook-ceph-rgw-nautiluss3.rook"
            - name: AWS_PUBLIC_ENDPOINT
              value: "s3-west.nrp-nautilus.io"
            - name: AWS_HTTPS
              value: "false"
            - name: AWS_VIRTUAL_HOSTING
              value: "FALSE"
            - name: GDAL_DATA
              value: "/opt/conda/share/gdal"
            - name: PROJ_LIB
              value: "/opt/conda/share/proj"
            - name: INDEX
              valueFrom:
                fieldRef:
                  fieldPath: metadata.annotations['batch.kubernetes.io/job-completion-index']
          resources:
            requests:
              cpu: "2"
              memory: 380Gi
              ephemeral-storage: "100Gi"
            limits:
              cpu: "2"
              memory: 380Gi
              ephemeral-storage: "200Gi"
          # Use the indexed environment variable to pass --i
          command:
            - bash
            - -lc
            - |
              python -u wetlands/repartition_nwi.py
      volumes:
        - name: repo
          emptyDir: {}


