This repository processes datasets typically used in our work in environment and biodiversity into cloud-optimized formats for visualization (PMTiles and COGS) and h3geo-indexed Parquet for computation with duckdb.  

Your job is to carefully follow the instructions and use the utilities here to generate and run the jobs to process additional datasets.  


These tasks are computationally intensive.  To scale to global datasets, we rely on deploying the process as a series of jobs on our large k8s cluster, NRP.  All data is pushed to the S3 Ceph cluster on NRP. 

A python helper package, cng_datasets, creates the kubernetes job yaml and provides the helper routines to perform the processing required for both raster and vector inputs. 


Once processed datasets are made, documentation of each dataset into both markdown and STAC catalog metadata uses an LLM-assisted workflow as described in DATASET_DOCUMENTATION_WORKFLOW.md

I will ask you to better document the process for generating these processed datasets and navigating some of the issues that arise, like OOM pods, as we get deeper in.  Let's try and get started.  

Try processing nrp:public-padus/raw/PADUS4_1Geodatabase.gdb.  

This has multiple layers.  Process the non-spatial layers to normal parquet, and for all multipolygon layers, create hexed versions following the style in this repo using the cng-datasets tool to generate the k8s. 

Your target resolution will be h10. Start be recognizing this is a vector dataset (geodatabase with multipolygon layers), so you will use the relevant vector worfklow.  

you can use local tools like gdal with vsicurl to peek at the layers, e.g. 

```
ogrinfo /vsicurl/https://s3-west.nrp-nautilus.io/public-padus/raw/PADUS4_1Geodatabase.gdb
```

likewise on the local system you can use rclone to browse buckets, e.g. 

```
rclone lsf nrp:public-padus
rclone lsf nrp:public-cpad
```

but remember any intensive process should be run as the k8s job, using it's faster network and greater cpu and storage. Figure out and document the right data organization for each of the sub-layers, compare to the example of nrp:public-cpad.  


Before we run anything, I want you to write detailed instructions to future agents so that they can read your documentation instead of having to study the source code.  I've noticed you've been looking a lot more at source files than reading markdown documents.  






This has been an evolving effort, and some early products were processed in less automated ways that may give rise to inconsistencies and need re-processing.  See todo.md

















Important notes on the Kubernetes cluster:  

- Our namespace is 'biodiversity'.  All jobs should be run in this namespace, you do not have access to other namespaces.
- Secrets required by the jobs (as generated by cng-datasets utility) should already be present in the namespace.
- The NRP k8s cluster is a shared academic resource. cng-datasets routine is careful to include important affinities that target nodes without GPUs, and importantly, allow for prememption. 
- The intensive 'hex' job utilizes up to 200 'completions'. Do not run more than 200 completions in a single job as this can overwhelm the k8s cluster's central etcd system. If necessary, an experimental mechanism called Armada can be used to handle arbitirarily large numbers of completions.  

Notes on S3 buckets: 

- All the final outputs are on the Ceph S3 system for the k8s cluster. 
- The S3 buckets can be accessed from outside the cluster on the address s3-west.nrp-nautilus.io.  It can also be accessed from inside the cluster, http://rook-ceph-rgw-nautiluss3.rook, much more efficiently.

- For additional availability, we will sync buckets to the source.coop S3 system, but with different bucket names and paths.  


